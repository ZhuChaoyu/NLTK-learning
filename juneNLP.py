# coding=utf-8


##### Standard sentence tokenizer.
####def sent_tokenize(text):
####    """
####    Return a sentence-tokenized copy of *text*,
####    using NLTK's recommended sentence tokenizer
####    (currently :class:`.PunktSentenceTokenizer`).
####    """
####    tokenizer = load('tokenizers/punkt/english.pickle')
####    return tokenizer.tokenize(text)
